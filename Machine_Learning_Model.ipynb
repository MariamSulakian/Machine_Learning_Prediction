{"nbformat_minor": 0, "cells": [{"source": "# Machine Learning Prediction Model\n#### by Mariam Sulakian\nMachine learning model, written in Python, to predict the outcome of the 2018 English Premier\nLeague (EPL)  football matches.  Built by training suitable machine\nlearning algorithms on historic results data.", "cell_type": "markdown", "metadata": {}}, {"source": "## Introduction\n\nI have built a machine learning model that looks at past EPL game data to predict future games in January 2018. Various attributes were studied including: total goals scored, total goals allowed, discipline (yellow cards, red cards, fouls incurred, total corners), shots per games, shots allowed per game, percentage of games won, defensive statistics (goalie saves, goalie save percentage, ratio of saves), and offensive statistics (scoringPercentage, scoring ratio). Various models were trained using these statistics and each team's outcome in the past games. KNN produced the highest accuracy with 56%. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Data\tImport\nImported native [Python libraries](https://docs.python.org/3.7/library/index.html) and [Scikit-Learn libraries](http://scikit-learn.org/stable/). Update the workspace_id, authorization_token, and endpoint to correspond to the 'Training.csv' file in azure, or you can alternatively use the link below to include a file path from your computer. A pathway can be easily produced through azure 'Generate Data Access Code'.", "cell_type": "markdown", "metadata": {}}, {"outputs": [{"text": "/home/nbuser\n", "output_type": "stream", "name": "stdout"}], "execution_count": 206, "source": "import sys\nsys.path.insert(0,\"/Users/Sulakian/anaconda3/lib/python3.6\")\nimport os \nprint(os.getcwd())", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 207, "source": "#import python libraries\nimport pandas as pd\nimport numpy as np\n\nimport sys\nimport math\nimport csv\nimport urllib\nimport collections\n\n#import Scikit-Learn libraries for implementation of machine learning algorithms \nimport sklearn", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 208, "source": "# Recursive Feature Elimination\nfrom sklearn import datasets\nfrom sklearn.feature_selection import RFE\nfrom sklearn.linear_model import LogisticRegression\n#feature importance\nfrom sklearn import metrics\nfrom sklearn.ensemble import ExtraTreesClassifier\n#to create predictions\nfrom sklearn.cross_validation import train_test_split\n#algorithms tested\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfrom sklearn.svm import LinearSVC\nfrom sklearn import linear_model\nfrom sklearn import tree\nfrom sklearn.cross_validation import cross_val_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.metrics import classification_report", "cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}}, {"source": "## Data Transformation and Exploration\nA year column was added to the data, as well as two columns with 'Winner' and 'Loser' with a none entry in each corresponding to a tie. Data was transformed in excel to produce the various statistics that would be included in the model (code can be found below for each metric). Feature selection was done with recursive feature elimination and feature importance quantification using Extra Trees Classifier to select for top 10 features. However, best results were achieved when all 14 features were included. ", "cell_type": "markdown", "metadata": {}}, {"source": "## Methodology Overview\nThis model takes in two teams and which year they will be compared in. So for 2018, 2017 data will be used since it is the most current season. The model will then predict the probability that each team will win. Many of the algorithms used require a numerical representation of attributes to conduct statistical analysis. Feature vectors are commonly used in machine learning model since they are n-dimensional vectors composed of numerical inputs. Since these models take in vectors as input, the statistics were transformed into vectors, one for each team, which could then be compared. The simplest way to compare the two vectors is to take the difference between them. The model will then use the resultant vector to predict the probability that each team will win. The model will then be composed of an x component which will be the difference vector and a y component, which will be 1 if team 1 wins, and 0 will be associated with the inverse of the difference. This will allow the model to introduce negative sampling by allowing the model to select against true negatives. ", "cell_type": "markdown", "metadata": {}}, {"source": "### Data Visualization", "cell_type": "markdown", "metadata": {}}, {"outputs": [{"execution_count": 209, "output_type": "execute_result", "data": {"text/plain": "   ID  Year       Date   HomeTeam    AwayTeam  FTHG  FTAG FTR  HTHG  HTAG  \\\n0   1  2005  13-Aug-05    Everton  Man United     0     2   A     0     1   \n1   2  2005  13-Aug-05   Man City   West Brom     0     0   D     0     0   \n2   3  2005  14-Aug-05    Arsenal   Newcastle     2     0   H     0     0   \n3   4  2005  20-Aug-05  Newcastle    West Ham     0     0   D     0     0   \n4   5  2005  21-Aug-05    Chelsea     Arsenal     1     0   H     0     0   \n\n     ...      HF  AF  HC  AC  HY  AY  HR  AR      Winner      Loser  \n0    ...      15  14   8   6   3   1   0   0  Man United    Everton  \n1    ...      13  11   3   6   2   3   0   0        None       None  \n2    ...      15  17   8   3   0   1   0   1     Arsenal  Newcastle  \n3    ...       9  11  10   2   1   1   0   1        None       None  \n4    ...      17  21   3   7   2   3   0   0     Chelsea    Arsenal  \n\n[5 rows x 26 columns]", "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n<\/style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>ID<\/th>\n      <th>Year<\/th>\n      <th>Date<\/th>\n      <th>HomeTeam<\/th>\n      <th>AwayTeam<\/th>\n      <th>FTHG<\/th>\n      <th>FTAG<\/th>\n      <th>FTR<\/th>\n      <th>HTHG<\/th>\n      <th>HTAG<\/th>\n      <th>...<\/th>\n      <th>HF<\/th>\n      <th>AF<\/th>\n      <th>HC<\/th>\n      <th>AC<\/th>\n      <th>HY<\/th>\n      <th>AY<\/th>\n      <th>HR<\/th>\n      <th>AR<\/th>\n      <th>Winner<\/th>\n      <th>Loser<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>2005<\/td>\n      <td>13-Aug-05<\/td>\n      <td>Everton<\/td>\n      <td>Man United<\/td>\n      <td>0<\/td>\n      <td>2<\/td>\n      <td>A<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>...<\/td>\n      <td>15<\/td>\n      <td>14<\/td>\n      <td>8<\/td>\n      <td>6<\/td>\n      <td>3<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>Man United<\/td>\n      <td>Everton<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>2<\/td>\n      <td>2005<\/td>\n      <td>13-Aug-05<\/td>\n      <td>Man City<\/td>\n      <td>West Brom<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>D<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>...<\/td>\n      <td>13<\/td>\n      <td>11<\/td>\n      <td>3<\/td>\n      <td>6<\/td>\n      <td>2<\/td>\n      <td>3<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>None<\/td>\n      <td>None<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>3<\/td>\n      <td>2005<\/td>\n      <td>14-Aug-05<\/td>\n      <td>Arsenal<\/td>\n      <td>Newcastle<\/td>\n      <td>2<\/td>\n      <td>0<\/td>\n      <td>H<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>...<\/td>\n      <td>15<\/td>\n      <td>17<\/td>\n      <td>8<\/td>\n      <td>3<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>Arsenal<\/td>\n      <td>Newcastle<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>4<\/td>\n      <td>2005<\/td>\n      <td>20-Aug-05<\/td>\n      <td>Newcastle<\/td>\n      <td>West Ham<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>D<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>...<\/td>\n      <td>9<\/td>\n      <td>11<\/td>\n      <td>10<\/td>\n      <td>2<\/td>\n      <td>1<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>1<\/td>\n      <td>None<\/td>\n      <td>None<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>5<\/td>\n      <td>2005<\/td>\n      <td>21-Aug-05<\/td>\n      <td>Chelsea<\/td>\n      <td>Arsenal<\/td>\n      <td>1<\/td>\n      <td>0<\/td>\n      <td>H<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>...<\/td>\n      <td>17<\/td>\n      <td>21<\/td>\n      <td>3<\/td>\n      <td>7<\/td>\n      <td>2<\/td>\n      <td>3<\/td>\n      <td>0<\/td>\n      <td>0<\/td>\n      <td>Chelsea<\/td>\n      <td>Arsenal<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<p>5 rows \u00c3\u0097 26 columns<\/p>\n<\/div>"}, "metadata": {}}], "execution_count": 209, "source": "from azureml import Workspace\nws = Workspace(\n    workspace_id='5cd0bcab12fa4e13bc1a21023ba57673',\n    authorization_token='COEXKjYaViYevjIKq+7hyXm+G9odq3v/8877WcEw7hy1VizII0IMoZGuX+crYHlY/vu8mRMEeTbD6eNxThA2bg==',\n    endpoint='https://studioapi.azureml.net'\n)\nds = ws.datasets['Training.csv']\nEPL_data = ds.to_dataframe()\nEPL_data['Date'] = EPL_data.Date.astype(str)\nEPL_data.head()", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 210, "source": "#Import the csv data\n#EPL_data = pd.read_csv('Training.csv')\n#EPL_data.head()", "cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}}, {"outputs": [{"execution_count": 211, "output_type": "execute_result", "data": {"text/plain": "      Team_Name\n11      Watford\n12    Newcastle\n13    Tottenham\n14    Liverpool\n15  Bournemouth", "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n<\/style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>Team_Name<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>11<\/th>\n      <td>Watford<\/td>\n    <\/tr>\n    <tr>\n      <th>12<\/th>\n      <td>Newcastle<\/td>\n    <\/tr>\n    <tr>\n      <th>13<\/th>\n      <td>Tottenham<\/td>\n    <\/tr>\n    <tr>\n      <th>14<\/th>\n      <td>Liverpool<\/td>\n    <\/tr>\n    <tr>\n      <th>15<\/th>\n      <td>Bournemouth<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>"}, "metadata": {}}], "execution_count": 211, "source": "#get list of teams in EPL that play in January 2018\nfrom azureml import Workspace\nws = Workspace(\n    workspace_id='5cd0bcab12fa4e13bc1a21023ba57673',\n    authorization_token='COEXKjYaViYevjIKq+7hyXm+G9odq3v/8877WcEw7hy1VizII0IMoZGuX+crYHlY/vu8mRMEeTbD6eNxThA2bg==',\n    endpoint='https://studioapi.azureml.net'\n)\nds = ws.datasets['Teams.csv']\nteam_names = ds.to_dataframe()\n#team_names.head()\n#team_names = pd.read_csv('Teams.csv')\n#dfList = df['one'].tolist()\nteamList = team_names['Team_Name'].tolist()\nteam_names.tail()", "cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}}, {"outputs": [{"text": "  Team_Name\n0   Arsenal\n", "output_type": "stream", "name": "stdout"}], "execution_count": 212, "source": "#test\nprint (team_names[team_names['Team_Name'] == 'Arsenal'])", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"text": "    Team_Name\n14  Liverpool\n", "output_type": "stream", "name": "stdout"}], "execution_count": 213, "source": "#test\nprint (team_names[team_names['Team_Name'] == 'Liverpool'])", "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "### Feature Creation\nUse a Support Vector Machine (SVM). Plot each data item as a point in a n-dimensional environment, where each feature is a value of a particular coordinate. Find the distance (subtraction) between two vectors. ", "cell_type": "markdown", "metadata": {}}, {"outputs": [], "execution_count": 254, "source": "#get annual vectors for each team\ndef getAnnualTeamData(teamName, year):\n    \n    annual_data = EPL_data[EPL_data['Year'] == year]\n    \n    # num goals scored in wins and losses\n    gamesHome = annual_data[annual_data['HomeTeam'] == teamName] \n    totalGoalsScored = gamesHome['FTHG'].sum()\n    gamesAway = annual_data[annual_data['AwayTeam'] == teamName]\n    totalGames = gamesHome.append(gamesAway)\n    numGames = len(totalGames.index)\n    #total goals scored\n    totalGoalsScored += gamesAway['FTAG'].sum()\n    # total goals allowed\n    totalGoalsAllowed = gamesHome['FTAG'].sum()\n    totalGoalsAllowed += gamesAway['FTHG'].sum()\n    \n    #discipline: total red cards, total yellow cards\n    totalYellowCards = gamesHome['HY'].sum()\n    totalYellowCards += gamesAway['AY'].sum()\n    totalRedCards = gamesHome['HR'].sum()\n    totalRedCards += gamesAway['AR'].sum()\n    \n    #total fouls\n    totalFouls = gamesHome['HF'].sum()\n    totalFouls += gamesAway['AF'].sum()\n    \n    #total Corners\n    totalCorners = gamesHome['HC'].sum()\n    totalCorners += gamesAway['AC'].sum()\n\n    #shots per game (spg) = total shots / total games \n    totalShots = gamesHome['HS'].sum()\n    # avg shots per game\n    totalShots += gamesAway['AS'].sum()\n    if numGames != 0:\n        spg = totalShots / numGames\n    # avg shots allowed per game\n    totalShotsAgainst = gamesHome['AS'].sum()\n    totalShotsAgainst += gamesAway['HS'].sum()\n    if numGames != 0:\n        sag = totalShotsAgainst / numGames\n    \n    #Games Won Percentage = Games Won / (Games Won + Games Lost) \n    gamesWon = annual_data[annual_data['Winner'] == teamName] \n    gamesLost = annual_data[annual_data['Loser'] == teamName] \n    numGamesWon = len(gamesWon.index)\n    numGamesLost = len(gamesLost.index)\n    if numGames != 0:\n        gamesWonPercentage = numGamesWon / numGames\n    \n    #Defense stats\n        #Goalie Saves = Shots on Goal - Goal Scored\n    totalShotsOnGoal = gamesHome['HST'].sum()\n    totalShotsOnGoal += gamesAway['AST'].sum()\n    goalieSaves = totalShotsOnGoal - totalGoalsAllowed\n    \n        #Saves Percentage = Goalie Saves / Shots on Goal   \n    if totalShotsOnGoal != 0:\n        savesPercentage = goalieSaves / totalShotsOnGoal\n        \n        #Saves Ratio = Shots On Goal / Goalie Saves    \n    if goalieSaves != 0:\n        savesRatio = totalShotsOnGoal / goalieSaves\n\n    #Offense stats\n        #Scoring Percentage = (Scoring Attempts - Goals Scored ) / Scoring Attempts\n    if totalShots != 0:\n        scoringPercentage = (totalShots - totalGoalsScored) / totalShots\n        \n        #Scoring Ratio = Shots On Goal / Goals Scored\n    if totalGoalsScored != 0:\n        scoringRatio = totalShotsOnGoal / totalGoalsScored       \n        \n            \n    if numGames == 0: #if team not in dataset\n        gamesWon = 0\n        gamesLost = 0\n        totalGoalsScored = 0\n        totalGoalsAllowed = 0\n        totalYellowCards = 0\n        totalRedCards = 0\n        totalFouls = 0\n        totalCorners = 0\n        spg = 0\n        sag = 0\n        gamesWonPercentage = 0\n        goalieSaves = 0\n        savesPercentage = 0\n        savesRatio = 0\n        scoringPercentage = 0\n        scoringRatio = 0 \n        \n    return [totalGoalsScored, totalGoalsAllowed, totalYellowCards, totalRedCards,\n        totalFouls,totalCorners, spg, sag, gamesWonPercentage, goalieSaves, savesPercentage, savesRatio,\n        scoringPercentage, scoringRatio]", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"execution_count": 215, "output_type": "execute_result", "data": {"text/plain": "[32, 24, 29, 2, 171, 110, 13, 12, 0, 62, 0, 1, 0, 2]"}, "metadata": {}}], "execution_count": 215, "source": "#test\ngetAnnualTeamData('Arsenal', 2017)", "cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}}, {"outputs": [{"execution_count": 216, "output_type": "execute_result", "data": {"text/plain": "[40, 42, 61, 5, 324, 173, 13, 11, 0, 100, 0, 1, 0, 3]"}, "metadata": {}}], "execution_count": 216, "source": "#test\ngetAnnualTeamData('Chelsea', 2015)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 217, "source": "#create a dictionary for all the team stats in a year for all the teams\ndef createAnnualDict(year):\n    annualDictionary = collections.defaultdict(list)\n    for team in teamList:\n        team_vector = getAnnualTeamData(team, year)\n        annualDictionary[team] = team_vector\n    return annualDictionary", "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [{"execution_count": 218, "output_type": "execute_result", "data": {"text/plain": "defaultdict(list,\n            {u'Arsenal': [58, 35, 40, 3, 310, 165, 14, 12, 0, 117, 0, 1, 0, 2],\n             u'Bournemouth': [36,\n              57,\n              43,\n              2,\n              313,\n              177,\n              10,\n              14,\n              0,\n              46,\n              0,\n              2,\n              0,\n              2],\n             u'Burnley': [15, 27, 25, 0, 171, 58, 8, 20, 0, 19, 0, 2, 0, 3],\n             u'Crystal Palace': [34,\n              59,\n              60,\n              0,\n              388,\n              175,\n              12,\n              14,\n              0,\n              58,\n              0,\n              2,\n              0,\n              3],\n             u'Everton': [35, 43, 49, 4, 334, 171, 12, 13, 0, 90, 0, 1, 0, 3],\n             u'Leicester': [47,\n              35,\n              48,\n              4,\n              359,\n              186,\n              12,\n              14,\n              0,\n              90,\n              0,\n              1,\n              0,\n              2],\n             u'Liverpool': [64,\n              42,\n              45,\n              2,\n              343,\n              209,\n              17,\n              10,\n              0,\n              142,\n              0,\n              1,\n              0,\n              2],\n             u'Man City': [62, 40, 54, 3, 348, 210, 15, 8, 0, 122, 0, 1, 0, 2],\n             u'Man United': [47,\n              34,\n              69,\n              2,\n              431,\n              186,\n              13,\n              11,\n              0,\n              112,\n              0,\n              1,\n              0,\n              3],\n             u'Newcastle': [22, 27, 18, 2, 177, 65, 11, 12, 0, 49, 0, 1, 0, 3],\n             u'Southampton': [44,\n              33,\n              42,\n              4,\n              364,\n              161,\n              13,\n              11,\n              0,\n              103,\n              0,\n              1,\n              0,\n              3],\n             u'Swansea': [40, 63, 51, 0, 371, 145, 11, 16, 0, 65, 0, 1, 0, 3],\n             u'Tottenham': [54,\n              31,\n              62,\n              0,\n              400,\n              219,\n              18,\n              10,\n              0,\n              166,\n              0,\n              1,\n              0,\n              3],\n             u'Watford': [29, 51, 70, 4, 426, 120, 10, 14, 0, 59, 0, 1, 0, 3],\n             u'West Brom': [39,\n              44,\n              60,\n              0,\n              366,\n              142,\n              10,\n              14,\n              0,\n              53,\n              0,\n              1,\n              0,\n              2],\n             u'West Ham': [52,\n              58,\n              61,\n              3,\n              346,\n              174,\n              14,\n              13,\n              0,\n              83,\n              0,\n              1,\n              0,\n              2]})"}, "metadata": {}}], "execution_count": 218, "source": "createAnnualDict(2016)", "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "# Model Training\nCreate training method that takes in a dictionary with with all the teams vectors by year. For each game, the function calculates the difference between between the team vectors for that year. Then, the function assigns a yTrain that is a 1 if the home team wins, and 0 otherwise. The difference vector becomes the input (xTrain) for the model, and a label (yTrain).", "cell_type": "markdown", "metadata": {}}, {"outputs": [], "execution_count": 253, "source": "def getTrainingData(years):\n    totalNumGames = 0\n    for year in years:\n        annual = EPL_data[EPL_data['Year'] == year]\n        totalNumGames += len(annual.index)\n    numFeatures = len(getAnnualTeamData('Arsenal',2015)) #random team, to find dimensionality\n    xTrain = np.zeros(( totalNumGames, numFeatures))\n    yTrain = np.zeros(( totalNumGames ))\n    indexCounter = 0\n    for year in years:\n        team_vectors = createAnnualDict(year)\n        annual = EPL_data[EPL_data['Year'] == year]\n        numGamesInYear = len(annual.index)\n        xTrainAnnual = np.zeros(( numGamesInYear, numFeatures))\n        yTrainAnnual = np.zeros(( numGamesInYear ))\n        counter = 0\n        for index, row in annual.iterrows():\n            h_team = row['HomeTeam']\n            h_vector = team_vectors[h_team]\n            a_team = row['AwayTeam']\n            a_vector = team_vectors[a_team]\n            diff = [a - b for a, b in zip(h_vector, a_vector)]\n            if (counter % 2 == 0):\n                if len(diff) != 0:\n                    xTrainAnnual[counter] = diff\n                yTrainAnnual[counter] = 1\n            # the opposite of the difference of the vectors should be a true negative, where team 1 does not win\n            else:\n                if len(diff) != 0:\n                    xTrainAnnual[counter] = [ -p for p in diff]\n                yTrainAnnual[counter] = 0\n            counter += 1\n        xTrain[indexCounter:numGamesInYear+indexCounter] = xTrainAnnual\n        yTrain[indexCounter:numGamesInYear+indexCounter] = yTrainAnnual\n        indexCounter += numGamesInYear\n    return xTrain, yTrain", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 220, "source": "#get the dictionary\nyears = range(2005,2017)\nxTrain, yTrain = getTrainingData(years)\nnp.save('xTrain', xTrain)\nnp.save('yTrain', yTrain)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"execution_count": 221, "output_type": "execute_result", "data": {"text/plain": "(1656, 14)"}, "metadata": {}}], "execution_count": 221, "source": "xTrain.shape", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"execution_count": 222, "output_type": "execute_result", "data": {"text/plain": "(1656,)"}, "metadata": {}}], "execution_count": 222, "source": "yTrain.shape", "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "## Feature Selection\n\nFeature selection of the 14 features is done through recursive feature elimination and a ranking of feature importance with extra trees classifier. 10 features of the 14 were determined to be much more influential. ", "cell_type": "markdown", "metadata": {}}, {"outputs": [], "execution_count": 223, "source": "model1 = LogisticRegression() #recursive feature elimination \nmodel2 = ExtraTreesClassifier() #feature importance", "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [{"text": "[ True  True  True False  True False  True  True False  True False  True\n False  True]\n[1 1 1 2 1 3 1 1 6 1 5 1 4 1]\n", "output_type": "stream", "name": "stdout"}], "execution_count": 224, "source": "# create the RFE model and select 3 attributes\nrfe = RFE(model1, 9)\nrfe = rfe.fit(xTrain, yTrain)\n# summarize the selection of the attributes\nprint(rfe.support_)\nprint(rfe.ranking_)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"text": "[ 0.09646106  0.09692582  0.10426811  0.09198217  0.11679977  0.11330094\n  0.082826    0.08832803  0.          0.0939929   0.          0.03201604\n  0.          0.08309918]\n", "output_type": "stream", "name": "stdout"}], "execution_count": 225, "source": "# Feature Importance\n#Top Features: total goals scored, total goals allowed, total yellow cards/red cards, total fouls, total corners,\n    #spg, sag, goalie saves, scoring ratio\n    \n#Lowest features: scoring percentage, saves percentage, games won percentage, save ratio\n    \n#fit an Extra Trees model to the data\nmodel2.fit(xTrain, yTrain)\n#display the relative importance of each attribute\nprint(model2.feature_importances_) #the higher the more important the feature", "cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}}, {"source": "### Updated Functions to include only top 10 features", "cell_type": "markdown", "metadata": {}}, {"outputs": [], "execution_count": 250, "source": "#updated function to include only top 10 features\ndef getAnnualTeamData2(teamName, year):\n    \n    annual_data = EPL_data[EPL_data['Year'] == year]\n    \n    # num goals scored in wins and losses\n    gamesHome = annual_data[annual_data['HomeTeam'] == teamName] \n    totalGoalsScored = gamesHome['FTHG'].sum()\n    gamesAway = annual_data[annual_data['AwayTeam'] == teamName]\n    totalGames = gamesHome.append(gamesAway)\n    numGames = len(totalGames.index)\n    #total goals scored\n    totalGoalsScored += gamesAway['FTAG'].sum()\n    # total goals allowed\n    totalGoalsAllowed = gamesHome['FTAG'].sum()\n    totalGoalsAllowed += gamesAway['FTHG'].sum()\n    \n    #discipline: total red cards, total yellow cards\n    totalYellowCards = gamesHome['HY'].sum()\n    totalYellowCards += gamesAway['AY'].sum()\n    totalRedCards = gamesHome['HR'].sum()\n    totalRedCards += gamesAway['AR'].sum()\n    \n    #total fouls\n    totalFouls = gamesHome['HF'].sum()\n    totalFouls += gamesAway['AF'].sum()\n    \n    #total Corners\n    totalCorners = gamesHome['HC'].sum()\n    totalCorners += gamesAway['AC'].sum()\n\n    #shots per game (spg) = total shots / total games \n    totalShots = gamesHome['HS'].sum()\n    # avg shots per game\n    totalShots += gamesAway['AS'].sum()\n    if numGames != 0:\n        spg = totalShots / numGames\n    # avg shots allowed per game\n    totalShotsAgainst = gamesHome['AS'].sum()\n    totalShotsAgainst += gamesAway['HS'].sum()\n    if numGames != 0:\n        sag = totalShotsAgainst / numGames\n    \n    #Games Won Percentage = Games Won / (Games Won + Games Lost) \n    gamesWon = annual_data[annual_data['Winner'] == teamName] \n    gamesLost = annual_data[annual_data['Loser'] == teamName] \n    numGamesWon = len(gamesWon.index)\n    numGamesLost = len(gamesLost.index)\n    if numGames != 0:\n        gamesWonPercentage = numGamesWon / numGames\n    \n    #Defense stats\n        #Goalie Saves = Shots on Goal - Goal Scored\n    totalShotsOnGoal = gamesHome['HST'].sum()\n    totalShotsOnGoal += gamesAway['AST'].sum()\n    goalieSaves = totalShotsOnGoal - totalGoalsAllowed\n    \n        #Saves Percentage = Goalie Saves / Shots on Goal   \n    if totalShotsOnGoal != 0:\n        savesPercentage = goalieSaves / totalShotsOnGoal\n        \n        #Saves Ratio = Shots On Goal / Goalie Saves    \n    if goalieSaves != 0:\n        savesRatio = totalShotsOnGoal / goalieSaves\n\n    #Offense stats\n        #Scoring Percentage = (Scoring Attempts - Goals Scored ) / Scoring Attempts\n    if totalShots != 0:\n        scoringPercentage = (totalShots - totalGoalsScored) / totalShots\n        \n        #Scoring Ratio = Shots On Goal / Goals Scored\n    if totalGoalsScored != 0:\n        scoringRatio = totalShotsOnGoal / totalGoalsScored       \n        \n            \n    if numGames == 0: #team not in dataset\n        totalGoalsScored = 0\n        totalGoalsAllowed = 0\n        totalYellowCards = 0\n        totalRedCards = 0\n        totalFouls = 0\n        totalCorners = 0\n        spg = 0\n        sag = 0\n        goalieSaves = 0\n        scoringRatio = 0\n        \n    return [totalGoalsScored, totalGoalsAllowed, totalYellowCards, totalRedCards,\n        totalFouls,totalCorners, spg, sag, goalieSaves, scoringRatio]", "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [{"execution_count": 227, "output_type": "execute_result", "data": {"text/plain": "[40, 42, 61, 5, 324, 173, 13, 11, 100, 3]"}, "metadata": {}}], "execution_count": 227, "source": "#test\ngetAnnualTeamData2('Chelsea', 2015)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 251, "source": "#updated functions to include only top 10 features\ndef createAnnualDict2(year):\n    annualDictionary = collections.defaultdict(list)\n    for team in teamList:\n        team_vector = getAnnualTeamData2(team, year)\n        annualDictionary[team] = team_vector\n    return annualDictionary", "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [{"execution_count": 231, "output_type": "execute_result", "data": {"text/plain": "defaultdict(list,\n            {u'Arsenal': [58, 35, 40, 3, 310, 165, 14, 12, 117, 2],\n             u'Bournemouth': [36, 57, 43, 2, 313, 177, 10, 14, 46, 2],\n             u'Burnley': [15, 27, 25, 0, 171, 58, 8, 20, 19, 3],\n             u'Crystal Palace': [34, 59, 60, 0, 388, 175, 12, 14, 58, 3],\n             u'Everton': [35, 43, 49, 4, 334, 171, 12, 13, 90, 3],\n             u'Leicester': [47, 35, 48, 4, 359, 186, 12, 14, 90, 2],\n             u'Liverpool': [64, 42, 45, 2, 343, 209, 17, 10, 142, 2],\n             u'Man City': [62, 40, 54, 3, 348, 210, 15, 8, 122, 2],\n             u'Man United': [47, 34, 69, 2, 431, 186, 13, 11, 112, 3],\n             u'Newcastle': [22, 27, 18, 2, 177, 65, 11, 12, 49, 3],\n             u'Southampton': [44, 33, 42, 4, 364, 161, 13, 11, 103, 3],\n             u'Swansea': [40, 63, 51, 0, 371, 145, 11, 16, 65, 3],\n             u'Tottenham': [54, 31, 62, 0, 400, 219, 18, 10, 166, 3],\n             u'Watford': [29, 51, 70, 4, 426, 120, 10, 14, 59, 3],\n             u'West Brom': [39, 44, 60, 0, 366, 142, 10, 14, 53, 2],\n             u'West Ham': [52, 58, 61, 3, 346, 174, 14, 13, 83, 2]})"}, "metadata": {}}], "execution_count": 231, "source": "createAnnualDict2(2016)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 252, "source": "#updated functions to include only top 10 features\ndef getTrainingData2(years):\n    totalNumGames = 0\n    for year in years:\n        annual = EPL_data[EPL_data['Year'] == year]\n        totalNumGames += len(annual.index)\n    numFeatures = len(getAnnualTeamData2('Arsenal',2015)) #random team, to find dimensionality\n    xTrain2 = np.zeros(( totalNumGames, numFeatures))\n    yTrain2 = np.zeros(( totalNumGames ))\n    indexCounter = 0\n    for year in years:\n        team_vectors = createAnnualDict2(year)\n        annual = EPL_data[EPL_data['Year'] == year]\n        numGamesInYear = len(annual.index)\n        xTrainAnnual = np.zeros(( numGamesInYear, numFeatures))\n        yTrainAnnual = np.zeros(( numGamesInYear ))\n        counter = 0\n        for index, row in annual.iterrows():\n            h_team = row['HomeTeam']\n            h_vector = team_vectors[h_team]\n            a_team = row['AwayTeam']\n            a_vector = team_vectors[a_team]\n            diff = [a - b for a, b in zip(h_vector, a_vector)]\n            if (counter % 2 == 0):\n                if len(diff) != 0:\n                    xTrainAnnual[counter] = diff\n                if h_team == row['Winner']:\n                    yTrainAnnual[counter] = 1\n                else: \n                    yTrainAnnual[counter] = 0\n            # the opposite of the difference of the vectors should be a true negative, where team 1 does not win\n            else:\n                if len(diff) != 0:\n                    xTrainAnnual[counter] = [ -p for p in diff]\n                yTrainAnnual[counter] = 0\n            counter += 1\n        xTrain2[indexCounter:numGamesInYear+indexCounter] = xTrainAnnual\n        yTrain2[indexCounter:numGamesInYear+indexCounter] = yTrainAnnual\n        indexCounter += numGamesInYear\n    return xTrain2, yTrain2", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 233, "source": "#get the dictionary\nyears = range(2005,2017)\nxTrain2, yTrain2 = getTrainingData2(years)\nnp.save('xTrain2', xTrain2)\nnp.save('yTrain2', yTrain2)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"execution_count": 234, "output_type": "execute_result", "data": {"text/plain": "(1656, 10)"}, "metadata": {}}], "execution_count": 234, "source": "xTrain2.shape", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"execution_count": 235, "output_type": "execute_result", "data": {"text/plain": "(1656,)"}, "metadata": {}}], "execution_count": 235, "source": "yTrain2.shape", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"text": "[[ -8.  15.   3. ...,   4. -25.   5.]\n [  5.   5. -15. ...,   5. -14.  -6.]\n [ -2.  -7.   0. ...,  -4.   1.   0.]\n ..., \n [ -2.  -2.   9. ...,  -2. -20.   0.]\n [  5. -11. -18. ...,  -3.  50.   1.]\n [ -4.  -6.  -8. ...,  -2. -19.  -1.]]\n", "output_type": "stream", "name": "stdout"}], "execution_count": 236, "source": "print xTrain2", "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "## Model Validation\nTraining all 14 features using linear Regression produced the most reliable results. Thus although the function gave the top 10 features to be most influential, all 14 were used to calculate the final results for optimal accuracy", "cell_type": "markdown", "metadata": {}}, {"source": "### Testing Models ALL 14 Features\nLinear Regression: 62%<br />\nSVM Regression: 50.7% (SVC)<br />\nSVM Classification: 46.9% (SVR)<br />\nDecision Tree (Classifier, Regressor): 49.3%, 52.9%<br />\nLogistic Regression: 45.2%<br />\nRandom Forest Classifier (n = 100): 50.4%<br />\nBayesian Ridge Regression: 49.3%<br />\nLasso Regression: 47.6%<br />\nRidge Regression or Tikhonov regularization (alpha = 0.5): 46.4%<br />\nAda-boost Classifier (n = 100): 49.0%<br />\nGradient Boosting Classifier (n = 100): 50.7%<br />\nGradient Boosting Regressor (n = 100): 47.8%<br />\nKNN (n = 60): 56.5%", "cell_type": "markdown", "metadata": {}}, {"source": "### Testing Models Top 10 Features\nLinear Regression: 57% <br />\nSVM Regression: 58.1% (SVC)<br />\nSVM Classification: 56.7% (SVR)<br />\nDecision Tree (Classifier, Regressor): 47.6%, 50.4%<br />\nLogistic Regression: 49.8%<br />\nRandom Forest Classifier (n = 100): 44.4%<br />\nBayesian Ridge Regression: 48.0%<br />\nLasso Regression: 41.2%<br />\nRidge Regression or Tikhonov regularization (alpha = 0.5): 41.8%<br />\nAda-boost Classifier (n = 100): 42.8%<br />\nGradient Boosting Classifier (n = 100): 51.6%<br />\nGradient Boosting Regressor (n = 100): 52.2%<br />", "cell_type": "markdown", "metadata": {}}, {"outputs": [], "execution_count": 248, "source": "# Tried all the following models. Uncomment model to try.\n\nlm = linear_model.LinearRegression()\n#lm = tree.DecisionTreeClassifier()\n#lm = tree.DecisionTreeRegressor()\n#lm = linear_model.LogisticRegression()\n#lm = linear_model.BayesianRidge()\n#lm = linear_model.Lasso()\n#lm = svm.SVC()\n#lm = svm.SVR()\n#lm = linear_model.Ridge(alpha = 0.5)\n#lm = AdaBoostClassifier(n_estimators=100)\n#lm = GradientBoostingClassifier(n_estimators=100) \n#lm = GradientBoostingRegressor(n_estimators=100, max_depth=9) \n#lm = RandomForestClassifier(n_estimators=100) \n#lm = KNeighborsClassifier(n_neighbors=60) #not possible with only 10 features", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"text": "(931, 14) (931,)\n(311, 14) (311,)\n0.639871382637\n", "output_type": "stream", "name": "stdout"}], "execution_count": 246, "source": "#use this\nxTrain, X_test, yTrain, y_test = train_test_split(xTrain, yTrain)\nprint xTrain.shape, yTrain.shape\nprint X_test.shape, y_test.shape\n#lm = linear_model.LinearRegression()\nmodel2 = lm.fit(xTrain, yTrain)\npredictions = lm.predict(X_test)\n#avg pred\nprint sum(predictions)/len(predictions)\n#print predictions", "cell_type": "code", "metadata": {"collapsed": false}}, {"source": "## Results\nI tested out the above models and selected the one with the highest prediction accuracy (linear regression). I then used this model to calculate the predictions for the 2018 games. ", "cell_type": "markdown", "metadata": {}}, {"outputs": [], "execution_count": 239, "source": "def createGamePrediction(team1_vector, team2_vector, xTrain, yTrain):\n    xTrain, X_test, yTrain, Y_test = train_test_split(xTrain, yTrain)\n    xTrain.shape, yTrain.shape\n    X_test.shape, y_test.shape\n    lm = linear_model.LinearRegression()\n    model2 = lm.fit(xTrain, yTrain)\n    diff = [a - b for a, b in zip(team1_vector, team2_vector)]\n    predictions = lm.predict(diff)\n    return predictions", "cell_type": "code", "metadata": {"collapsed": true}}, {"outputs": [{"text": "Probability that Everton wins: 0.472145799553\nProbability that Arsenal wins: 0.516087854472\n", "output_type": "stream", "name": "stdout"}], "execution_count": 240, "source": "team1_vector = getAnnualTeamData(\"Arsenal\", 2017)\nteam2_vector = getAnnualTeamData(\"West Brom\", 2017)\nteam3_vector = getAnnualTeamData(\"Chelsea\", 2017)\n\nprint 'Probability that ' + team1_name + ' wins:',createGamePrediction(team1_vector, team2_vector,xTrain, yTrain)\nprint 'Probability that ' + team2_name + ' wins:',createGamePrediction(team2_vector, team1_vector,xTrain, yTrain)", "cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}}, {"source": "# Final Predictions on Test Set\nFinal predictions are based on the probability that first team (Home Team) wins. The probabilities are as follows:<br />\n1) Arsenal\tCrystal Palace 53.6%<br />\n2) Burnley\tMan United 49.6%<br />\n3) Everton\tWest Brom 51.4%<br />\n4) Leicester\tWatford 54.4%<br />\n5) Man City\tNewcastle 77.4%<br />\n6) Southampton\tTottenham 55.9%<br />\n7) Swansea\tLiverpool 47.3%<br />\n8) West Ham\tBournemouth 58.96%<br />", "cell_type": "markdown", "metadata": {}}, {"outputs": [{"execution_count": 241, "output_type": "execute_result", "data": {"text/plain": "   Game_ID  Year       Date   HomeTeam        AwayTeam\n0        1  2018  20-Jan-18    Arsenal  Crystal Palace\n1        2  2018  20-Jan-18    Burnley      Man United\n2        3  2018  20-Jan-18    Everton       West Brom\n3        4  2018  20-Jan-18  Leicester         Watford\n4        5  2018  20-Jan-18   Man City       Newcastle", "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n<\/style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th><\/th>\n      <th>Game_ID<\/th>\n      <th>Year<\/th>\n      <th>Date<\/th>\n      <th>HomeTeam<\/th>\n      <th>AwayTeam<\/th>\n    <\/tr>\n  <\/thead>\n  <tbody>\n    <tr>\n      <th>0<\/th>\n      <td>1<\/td>\n      <td>2018<\/td>\n      <td>20-Jan-18<\/td>\n      <td>Arsenal<\/td>\n      <td>Crystal Palace<\/td>\n    <\/tr>\n    <tr>\n      <th>1<\/th>\n      <td>2<\/td>\n      <td>2018<\/td>\n      <td>20-Jan-18<\/td>\n      <td>Burnley<\/td>\n      <td>Man United<\/td>\n    <\/tr>\n    <tr>\n      <th>2<\/th>\n      <td>3<\/td>\n      <td>2018<\/td>\n      <td>20-Jan-18<\/td>\n      <td>Everton<\/td>\n      <td>West Brom<\/td>\n    <\/tr>\n    <tr>\n      <th>3<\/th>\n      <td>4<\/td>\n      <td>2018<\/td>\n      <td>20-Jan-18<\/td>\n      <td>Leicester<\/td>\n      <td>Watford<\/td>\n    <\/tr>\n    <tr>\n      <th>4<\/th>\n      <td>5<\/td>\n      <td>2018<\/td>\n      <td>20-Jan-18<\/td>\n      <td>Man City<\/td>\n      <td>Newcastle<\/td>\n    <\/tr>\n  <\/tbody>\n<\/table>\n<\/div>"}, "metadata": {}}], "execution_count": 241, "source": "#test_data = pd.read_csv('Data/test.csv')\nfrom azureml import Workspace\nws = Workspace(\n    workspace_id='5cd0bcab12fa4e13bc1a21023ba57673',\n    authorization_token='COEXKjYaViYevjIKq+7hyXm+G9odq3v/8877WcEw7hy1VizII0IMoZGuX+crYHlY/vu8mRMEeTbD6eNxThA2bg==',\n    endpoint='https://studioapi.azureml.net'\n)\nds = ws.datasets['Test.csv']\ntest_data = ds.to_dataframe()\n(test_data.head())", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"text": "0.428688538701\n", "output_type": "stream", "name": "stdout"}], "execution_count": 242, "source": "team1_vector = getAnnualTeamData(\"Arsenal\", 2017)\nteam2_vector = getAnnualTeamData(\"Crystal Palace\", 2017)\nprint createGamePrediction(team1_vector, team2_vector,xTrain, yTrain)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"text": "0.545627382987\n", "output_type": "stream", "name": "stdout"}], "execution_count": 243, "source": "team1_vector = getAnnualTeamData(\"Burnley\", 2017)\nteam2_vector = getAnnualTeamData(\"Man United\", 2017)\nprint createGamePrediction(team1_vector, team2_vector,xTrain, yTrain)", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [], "execution_count": 255, "source": "#game_ID given to each game to simplify identification of game\ndef formulatePredictions():\n    probs = [[0 for x in range(2)] for x in range(len(test_data.index))]\n    for index, row in test_data.iterrows():\n        game_ID = row['Game_ID']\n        year = row['Year'] - 1\n        team1_Name = row['HomeTeam']\n        team2_Name = row['AwayTeam']\n        team1_vector = getAnnualTeamData(team1_Name, year)\n        team2_vector = getAnnualTeamData(team2_Name, year)\n        prediction = createGamePrediction(team1_vector, team2_vector,xTrain, yTrain)\n        probs[index][0] = game_ID\n        probs[index][1] = prediction\n    probs = pd.np.array(probs)\n    return probs", "cell_type": "code", "metadata": {"collapsed": false}}, {"outputs": [{"execution_count": 249, "output_type": "execute_result", "data": {"text/plain": "array([[ 1.        ,  0.53643911],\n       [ 2.        ,  0.49611248],\n       [ 3.        ,  0.51446088],\n       [ 4.        ,  0.54425525],\n       [ 5.        ,  0.77397612],\n       [ 6.        ,  0.55895189],\n       [ 7.        ,  0.47308558],\n       [ 8.        ,  0.58962172]])"}, "metadata": {}}], "execution_count": 249, "source": "formulatePredictions()", "cell_type": "code", "metadata": {"collapsed": false, "scrolled": true}}, {"source": "## References\n1. **Background reading:**<br />\n    * Brucher, Matthieu, et al. \u00e2\u0080\u009cScikit-Learn: Machine Learning in Python.\u00e2\u0080\u009d Edited by Mikio Braun, Journal of Machine Learning Research, 2011, [www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf](http://www.jmlr.org/papers/volume12/pedregosa11a/pedregosa11a.pdf).\n    * Demsar, Janez, and Blaz Tupan. From Experimental Machine Learning to Interactive Data Mining. Orange, [www.celta.paris-sorbonne.fr/anasem/papers/miscelanea/InteractiveDataMining.pdf](http://www.celta.paris-sorbonne.fr/anasem/papers/miscelanea/InteractiveDataMining.pdf).\n    * Dewey, Conor. \u00e2\u0080\u009cThe Hitchhiker's Guide to Machine Learning in Python.\u00e2\u0080\u009d FreeCodeCamp, FreeCodeCamp, 1 Aug. 2017, [medium.freecodecamp.org/the-hitchhikers-guide-to-machine-learning-algorithms-in-python-bfad66adb378](https://medium.freecodecamp.org/the-hitchhikers-guide-to-machine-learning-algorithms-in-python-bfad66adb378)/ \n    * Kaufmann, Morgan. \u00e2\u0080\u009cData Mining: Practical Machine Learning Tools and Techniques.\u00e2\u0080\u009d Edited by Diane Cerra, Research Gate, Nov. 2010, [www.researchgate.net/publication/220017784_Data_Mining_Practical_Machine_Learning_Tools_and_Techniques.](https://www.researchgate.net/profile/Ian_Witten/publication/220017784_Data_Mining_Practical_Machine_Learning_Tools_and_Techniques/links/00b495175e36c6f402000000.pdf).\n    * Paruchuri, Vik. \u00e2\u0080\u009cMachine Learning with Python.\u00e2\u0080\u009d Dataquest, Dataquest, 14 Dec. 2017, [www.dataquest.io/blog/machine-learning-python/](https://www.dataquest.io/blog/machine-learning-python/).\n    * \u00e2\u0080\u009cAn Introduction to Machine Learning with Scikit-Learn.\u00e2\u0080\u009d Scikit-Learn, Scikit-Learn Developers, [scikit-learn.org/stable/tutorial/basic/tutorial.html](http://scikit-learn.org/stable/tutorial/basic/tutorial.html).\n    * Raghavan, Shreyas. \u00e2\u0080\u009cCreate a Model to Predict House Prices Using Python.\u00e2\u0080\u009d Towards Data Science, 17 June 2017, [towardsdatascience.com/create-a-model-to-predict-house-prices-using-python-d34fe8fad88f](https://towardsdatascience.com/create-a-model-to-predict-house-prices-using-python-d34fe8fad88f).\n2. **Source used to find the common statistics calculated for football teams:** <br /> \u00e2\u0080\u009cWellington Phoenix.\u00e2\u0080\u009d Soccer Betting Statistics and Results for Wellington Phoenix, Soccer Betting Statistics 2018, 2018, [www.soccerbettingstatistics.com/team/wellington-phoenix/2017-2018/a-league/6282/53/1086](www.soccerbettingstatistics.com/team/wellington-phoenix/2017-2018/a-league/6282/53/1086).\n<br />\n3. **Feature vectors inspiration:** <br /> Agarwal, Sumeet. Machine Learning: A Very Quick Introduction. 6 Jan. 2013, [web.iitd.ac.in/~sumeet/mlintro_doc.pdf](web.iitd.ac.in/~sumeet/mlintro_doc.pdf).\n<br />\n4. **Research/background reading on explanations of Word2Vec - representing words with attributes in a vector, then subtracting those vectors to find the difference between them.**\n    * \u00e2\u0080\u009cWhy word2vec works.\u00e2\u0080\u009d Galvanize, [blog.galvanize.com/add-and-subtract-words-like-vectors-with-word2vec-2/](http://andyljones.tumblr.com/post/111299309808/why-word2vec-works).\n    * \u00e2\u0080\u009cVector Representations of Words.\u00e2\u0080\u009d TensorFlow, 2 Nov. 2017, [www.tensorflow.org/tutorials/word2vec](https://www.tensorflow.org/tutorials/word2vec).\n    * \u00e2\u0080\u009cAdd and Subtract Words like Vectors with word2vec.\u00e2\u0080\u009d Galvanize, [blog.galvanize.com/add-and-subtract-words-like-vectors-with-word2vec-2/](http://blog.galvanize.com/add-and-subtract-words-like-vectors-with-word2vec-2/).\n    * Critchlow, Will. \u00e2\u0080\u009cA Beginner's Guide to word2vec AKA What's the Opposite of Canada?\u00e2\u0080\u009d Distilled, 28 Jan. 2016, [www.distilled.net/resources/a-beginners-guide-to-word2vec-aka-whats-the-opposite-of-canada/](https://www.distilled.net/resources/a-beginners-guide-to-word2vec-aka-whats-the-opposite-of-canada/).\n<br />\n5. **Feature Selection inspiration:** <br /> \u00e2\u0080\u009cFeature Selection in Python with Scikit-Learn.\u00e2\u0080\u009d Machine Learning Mastery, 21 Sept. 2016, [machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/](machinelearningmastery.com/feature-selection-in-python-with-scikit-learn/).\n<br />\n6. **Approach inspiration taken from:** <br /> Forsyth, Jared, and Andrew Wilde. \u00e2\u0080\u009cA Machine Learning Approach to March Madness.\u00e2\u0080\u009d Brigham Young University, 2014, [axon.cs.byu.edu/~martinez/classes/478/stuff/Sample_Group_Project3.pdf](http://axon.cs.byu.edu/~martinez/classes/478/stuff/Sample_Group_Project3.pdf).\n", "cell_type": "markdown", "metadata": {}}], "nbformat": 4, "metadata": {"kernelspec": {"language": "python", "display_name": "Python 2", "name": "python2"}, "language_info": {"mimetype": "text/x-python", "nbconvert_exporter": "python", "pygments_lexer": "ipython2", "name": "python", "codemirror_mode": {"version": 2, "name": "ipython"}, "version": "2.7.13", "file_extension": ".py"}}}